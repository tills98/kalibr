#!/usr/bin/env python3
import itertools

print("importing libraries")
import sm
import aslam_cv as acv
import aslam_cv_backend as acvb
import kalibr_common as kc
import kalibr_camera_calibration as kcc
import incremental_calibration as ic
import aslam_backend as aopt
from kalibr_camera_calibration.CameraCalibrator import OptimizationDiverged

import cv2
import os
import numpy as np
from scipy.spatial.transform import Rotation
import multiprocessing
import pylab as pl
import argparse
import sys
import random
import signal
import pickle as pkl
import glob


#available models
cameraModels = { 'pinhole-radtan': acvb.DistortedPinhole,
                 'pinhole-equi':   acvb.EquidistantPinhole,
                 'pinhole-fov':    acvb.FovPinhole,
                 'omni-none':      acvb.Omni,
                 'omni-radtan':    acvb.DistortedOmni,
                 'eucm-none':      acvb.ExtendedUnified,
                 'ds-none':        acvb.DoubleSphere}

# DV group ids
CALIBRATION_GROUP_ID = 0
LANDMARK_GROUP_ID = 1
TRANSFORMATION_GROUP_ID = 2

glob_rerrs = []

def build_T(R, t):
    print(t.shape)
    T = np.eye(4)
    T[:3, :3] = R
    T[:3, 3] = t[:,0]

    return T


def build_between_board_vecs(rvec_world1_to_cam, tvec_world1_to_cam, rvec_world2_to_cam, tvec_world2_to_cam):
    """

    :param R_world1_to_cam: 3x1 rotation vector or 3x3 rotation matrix
    :param t_world1_to_cam:
    :param R_world2_to_cam: 3x1 rotation vector or 3x3 rotation matrix
    :param t_world2_to_cam:
    :return:
    """

    # Invert transformations (from world to cam --> cam to world)
    R_world1_to_cam = cv2.Rodrigues(rvec_world1_to_cam)[0] if rvec_world1_to_cam.shape == (3,1) else rvec_world1_to_cam
    R_cam_to_world1 = R_world1_to_cam.T

    R_world2_to_cam = cv2.Rodrigues(rvec_world2_to_cam)[0] if rvec_world2_to_cam.shape == (3,1) else rvec_world2_to_cam
    R_cam_to_world2 = R_world2_to_cam.T

    R_world1_to_world2 = R_cam_to_world2 @ R_world1_to_cam
    t_world1_to_world2 = R_cam_to_world2 @ (tvec_world1_to_cam - tvec_world2_to_cam)

    # Ensure the rotation matrix is orthonormal
    U, _, Vt = np.linalg.svd(R_world1_to_world2)
    R_world1_to_world2 = U @ Vt  # Enforce orthogonality

    rvec_world1_to_world2 = cv2.Rodrigues(R_world1_to_world2)[0]

    return rvec_world1_to_world2, t_world1_to_world2

def build_between_board_T_ex(T_world1_to_cam, T_world2_to_cam):
    """

    :param R_world1_to_cam: 3x1 rotation vector or 3x3 rotation matrix
    :param t_world1_to_cam:
    :param R_world2_to_cam: 3x1 rotation vector or 3x3 rotation matrix
    :param t_world2_to_cam:
    :return:
    """

    # Invert transformations (from world to cam --> cam to world)
    # R_world1_to_cam = cv2.Rodrigues(rvec_world1_to_cam)[0] if rvec_world1_to_cam.shape == (3,1) else rvec_world1_to_cam
    # R_cam_to_world1 = R_world1_to_cam.T
    #
    # R_world2_to_cam = cv2.Rodrigues(rvec_world2_to_cam)[0] if rvec_world2_to_cam.shape == (3,1) else rvec_world2_to_cam
    # R_cam_to_world2 = R_world2_to_cam.T
    #
    # R_world1_to_world2 = R_cam_to_world2 @ R_world1_to_cam
    # t_world1_to_world2 = R_cam_to_world2 @ (tvec_world1_to_cam - tvec_world2_to_cam)
    #
    # return cv2.Rodrigues(R_world1_to_world2)[0], t_world1_to_world2


def build_camera_matrix(p):
    C = np.eye(3)
    C[0,0] = p[0]
    C[1,1] = p[1]
    C[0,2] = p[2]
    C[1,2] = p[3]

    return C



class JointCalibrationTargetOptimizationProblem(ic.CalibrationOptimizationProblem):
    @classmethod
    def from_given_intrinsics(cls, cams, Rs: [np.ndarray], ts: [np.ndarray], objpoints: [np.ndarray], imgpoints: [np.ndarray]) -> ic.CalibrationOptimizationProblem:
        """
        Build the joint calibration target optimization problem for pinhole rad-tan cameras.

        All input parameters should be organized per board (like as follows: [board0, board1, board2, ...])

        :param camera_intrinsics: intrinsics for each board
        :param distortions: distortions for each board
        :param Rs: R for each board
        :param ts: t for each board
        :param objpoints: target points for each board
        :param imgpoints: image points for each board
        :return: Hopefully that what we want
        """

        print("------ problem definition ------")

        num_boards = len(cams)

        print("num_boards", num_boards)

        assert len(Rs) == num_boards
        assert len(ts) == num_boards
        assert len(objpoints) == num_boards
        assert len(imgpoints) == num_boards

        print("cams", cams)

        rval = JointCalibrationTargetOptimizationProblem()

        rval.rerrs = dict()

        # build cams for each of our shapes
        for i in range(num_boards):
            glob_rerrs.append([])

        R_combs = itertools.combinations(Rs, 2)
        t_combs = itertools.combinations(ts, 2)

        print("R_combs", R_combs)
        print("t_combs", t_combs)

        Ts_target_cam_dv = []

        # add camera design variables to the problem
        for idx, cam in enumerate(cams):
            cam.setDvActiveStatus(True, True, False)
            rval.addDesignVariable(cam.dv.distortionDesignVariable(), CALIBRATION_GROUP_ID)
            rval.addDesignVariable(cam.dv.projectionDesignVariable(), CALIBRATION_GROUP_ID)
            rval.addDesignVariable(cam.dv.shutterDesignVariable(), CALIBRATION_GROUP_ID)

        # add all target-to-cam transformations as design variables to our problem
        for board_idx, (R, t) in enumerate(zip(Rs, ts)):
            T_target_cam = build_T(R, t)
            T_target_cam_dv = aopt.TransformationDv(sm.Transformation(T_target_cam))

            Ts_target_cam_dv.append((T_target_cam, T_target_cam_dv))

            for i in range(0, T_target_cam_dv.numDesignVariables()):
                rval.addDesignVariable(T_target_cam_dv.getDesignVariable(i), TRANSFORMATION_GROUP_ID)

        # iterate over 2-combinations of the boards
        rerr_idx = 0
        for board_idx, (R_comb, t_comb) in enumerate(zip(list(R_combs), list(t_combs))):
            R_target1_cam = R_comb[0]
            t_target1_cam = t_comb[0]
            R_target2_cam = R_comb[1]
            t_target2_cam = t_comb[1]

            rvec_t1_t2, t_t1_t2 = build_between_board_vecs(R_target1_cam, t_target1_cam, R_target2_cam, t_target2_cam)
            R_t1_t2 = cv2.Rodrigues(rvec_t1_t2)[0]
            print("R_t1_t2", R_t1_t2)
            print("t_t1_t2", t_t1_t2)

            T_target1_cam = build_T(R_target1_cam, t_target1_cam)
            T_target2_cam = build_T(R_target2_cam, t_target2_cam)
            T_t1_t2 = build_T(R_t1_t2, t_t1_t2)

            # create design variables
            T_target1_cam_dv = [T_target_cam_dv for T_target_cam, T_target_cam_dv in Ts_target_cam_dv if np.array_equal(T_target_cam, T_target1_cam)][0]
            T_target1_cam_ex = T_target1_cam_dv.toExpression()
            T_target2_cam_dv = [T_target_cam_dv for T_target_cam, T_target_cam_dv in Ts_target_cam_dv if np.array_equal(T_target_cam, T_target2_cam)][0]
            T_target2_cam_ex = T_target2_cam_dv.toExpression()

            print("sm r2quat", sm.r2quat(R_t1_t2))
            print("R^-1 @ R", np.linalg.inv(R_t1_t2) @ R_t1_t2)

            T_t1_t2_dv = aopt.TransformationDv(sm.Transformation(T_t1_t2))
            T_t1_t2_ex = T_t1_t2_dv.toExpression()

            # add boards-in-between transformations as design variables to our problem
            # TODO: unsure that this should be there
            for i in range(0, T_t1_t2_dv.numDesignVariables()):
                rval.addDesignVariable(T_t1_t2_dv.getDesignVariable(i), TRANSFORMATION_GROUP_ID)

            # copied from CameraCalibrator -> CalibrationTargetOptimizationProblem
            # \todo pass in the detector uncertainty somehow.
            cornerUncertainty = 1.0
            R = np.eye(2) * cornerUncertainty * cornerUncertainty
            invR = np.linalg.inv(R)

            rval.rerrs[board_idx] = list()

            print(f"error definitions for board {board_idx}:")
            for y, p_t1 in zip(imgpoints[board_idx], objpoints[board_idx]):
                print(" - reprojection error defintion")
                cam_id = board_idx
                cam = cams[cam_id]

                print("   y:", y.reshape((2,1)).shape)
                print("   p_t1:", p_t1.flatten())
                print("   R:", R.flatten())

                print("   T_target2_cam:", T_target2_cam.shape)
                print("   T_t1_t2:", T_t1_t2.shape)

                p_t1_dv = aopt.HomogeneousPointDv(sm.toHomogeneous(p_t1))
                p_t1_dv.setActive(False)
                p_t1_ex = p_t1_dv.toExpression()

                # add world point to design variables
                rval.addDesignVariable(p_t1_dv, LANDMARK_GROUP_ID)

                p_t1_w = np.ones((4,1))
                p_t1_w[:3,0] = p_t1

                test_ex = T_target2_cam_ex * T_target1_cam_ex * p_t1_ex

                projected_y_ex = T_target2_cam_ex * T_t1_t2_ex * p_t1_ex
                print("   projected_y_ex homogeneous:", projected_y_ex.toHomogeneous())
                # projected_y_ex = T_target1_cam_ex * p_t1_ex
                projected_y = T_target2_cam @ T_t1_t2 @ p_t1_w
                # print("   test_ex:", test_ex.toHomogeneous())
                # print("   projected_y:", projected_y)

                projected_y_short = projected_y[:3,0]
                # print("   projected_y_short:", projected_y_short.flatten())

                # hom_projected_y_short = aopt.HomogeneousPointDv(sm.toHomogeneous(projected_y_short))
                # print("   hom_projected_y_short.toExpression():", hom_projected_y_short.toExpression().toHomogeneous())

                # Create an error term
                rerr = cam.model.reprojectionError(y, invR, projected_y_ex, cam.dv)
                rerr.idx = rerr_idx

                rerr_idx += 1

                # add blake-zisserman mest
                mest = aopt.BlakeZissermanMEstimator(2.0)
                rerr.setMEstimatorPolicy(mest)

                glob_rerrs[board_idx].append(rerr)

                # add error term to the problem
                rval.addErrorTerm(rerr)
                rval.rerrs[board_idx].append(rerr)

        return rval

    @classmethod
    def build_camera_geometry(self, camera_intrinsics, distortions):
        params = np.array([camera_intrinsics[0, 0], camera_intrinsics[1, 1], camera_intrinsics[0, 2], camera_intrinsics[1, 2]])
        dist_coeff = distortions[0]

        dist = acv.RadialTangentialDistortion(dist_coeff[0], dist_coeff[1], dist_coeff[2], dist_coeff[3])

        proj = acv.DistortedPinholeProjection(params[0], params[1],
                                              params[2], params[3],
                                              6040, 4080,
                                              dist)

        geometry = acv.DistortedPinholeCameraGeometry(proj)

        return geometry

    @classmethod
    def build_target_coordinate_dvs(cls, objpoints):
        P_t_dv = []
        P_t_ex = []

        for p in objpoints:
            p_t_dv = aopt.HomogeneousPointDv(sm.toHomogeneous(p))  # self.target.point(i) is a point from the target expressed in the target frame (_points in GridCalibrationTargetAprilgrid.(hpp/cpp))
            p_t_dv.setActive(True)
            p_t_ex = p_t_dv.toExpression()
            P_t_dv.append(p_t_dv)
            P_t_ex.append(p_t_ex)

        return P_t_dv, P_t_ex


def main():
    base_path = "/data"

    print("load data")

    # load intrinsics, extrinsics and 3d points
    mtx6 = np.load(f"{base_path}/res/mtx6.npy")
    dist6 = np.load(f"{base_path}/res/dist6.npy")
    rvecs6 = np.load(f"{base_path}/res/rvecs6.npy")
    tvecs6 = np.load(f"{base_path}/res/tvecs6.npy")
    #with open(f"{base_path}/res/objpoints6.pkl", "rb") as f: objpoints6 = pkl.load(f)
    #with open(f"{base_path}/res/imgp6.pkl", "rb") as f: imgp6 = pkl.load(f)

    mtx7 = np.load(f"{base_path}/res/mtx7.npy")
    dist7 = np.load(f"{base_path}/res/dist7.npy")
    rvecs7 = np.load(f"{base_path}/res/rvecs7.npy")
    tvecs7 = np.load(f"{base_path}/res/tvecs7.npy")
    #with open(f"{base_path}/res/objpoints7.pkl", "rb") as f: objpoints7 = pkl.load(f)
    #with open(f"{base_path}/res/imgp7.pkl", "rb") as f: imgp7 = pkl.load(f)

    mtx8 = np.load(f"{base_path}/res/mtx8.npy")
    dist8 = np.load(f"{base_path}/res/dist8.npy")
    rvecs8 = np.load(f"{base_path}/res/rvecs8.npy")
    tvecs8 = np.load(f"{base_path}/res/tvecs8.npy")
    #with open(f"{base_path}/res/objpoints8.pkl", "rb") as f: objpoints8 = pkl.load(f)
    #with open(f"{base_path}/res/imgp8.pkl", "rb") as f: imgp8 = pkl.load(f)

    # set number of boards
    num_boards = 3

    # load image and object points from our calibration data
    print("load image and objpoints")
    imgps = []
    objps = []

    for b in range(num_boards):
        imgps.append([])
        objps.append([])

        # our board files are numerated by their shape on one axis (0 -> 6 -> 6x6 board, ...)
        bproj = b + 6

        print("b", b)
        print("bproj", bproj)
        print("path", f"{base_path}/res/imgpoints/board{bproj}_imgp_*")

        imgp_files = glob.glob(f"{base_path}/res/imgpoints/board{bproj}_imgp_*")
        imgp_files.sort()

        objp_files = glob.glob(f"{base_path}/res/objpoints/board{bproj}_objp_*")
        objp_files.sort()

        print("files", imgp_files)
        print("files", objp_files)

        for file in imgp_files:
            imgp = np.loadtxt(f"{file}")
            imgps[b].append(imgp)

        for file in objp_files:
            o = np.loadtxt(f"{file}")
            objps[b].append(o)

    # calculate views
    num_views = len(imgps[0])  # all board entries have the same amount of images
    print(f"amount of views per board (boardid: imagepoints / worldpoints):")
    for b in range(num_boards):
        print(f" - {b}: {len(imgps[b])} / {len(objps[b])}")

    # setup intrinsics and distortions
    print("setup intrinsics and distortions")
    camera_intrinsics = [mtx6, mtx7, mtx8]
    distortions = [dist6, dist7, dist8]

    print(" - camera_intrinsics:")
    for b in range(num_boards):
        print(f"   -> {b}: {camera_intrinsics[b]}")
    print(" - distortions:")
    for b in range(num_boards):
        print(f"   -> {b}: {distortions[b]}")


    # limit attempts
    restart_attempts = 3

    while True:
        try:
            # build camera geometry
            cams = []

            print("setup camera geometry for each board calibration")
            for i in range(num_boards):
                cam_geometry = JointCalibrationTargetOptimizationProblem.build_camera_geometry(camera_intrinsics[i], distortions[i])
                cam = kcc.CameraGeometry(cameraModel=cameraModels["pinhole-radtan"], targetConfig=None, dataset=None,
                                         geometry=cam_geometry)
                cams.append(cam)
                glob_rerrs.append([])

            # init incremental estimator
            estimator = ic.IncrementalEstimator(CALIBRATION_GROUP_ID)
            linearSolverOptions = estimator.getLinearSolverOptions()
            optimizerOptions = estimator.getOptimizerOptions()
            estimatorOptions = estimator.getOptions()

            # set linear solver options
            linearSolverOptions.columnScaling = True
            linearSolverOptions.verbose = True
            linearSolverOptions.epsSVD = 1e-6

            # set optimizer options
            optimizerOptions.maxIterations = 50
            # optimizerOptions.nThreads = max(1, multiprocessing.cpu_count()-6)
            optimizerOptions.nThreads = 1
            optimizerOptions.verbose = True

            # set estimator options
            estimatorOptions.verbose = True

            # futher options
            force = False

            # ----
            views = []

            progress = sm.Progress2(num_views)
            progress.sample()

            # append problems for each image
            for i in range(num_views):
                print("=======================================================================")
                print(f"Optimize projection and distortion for view #{i} ...")

                # solvePnP for the rvecs and tvecs
                # print optimized paramters

                transformations = []

                # solvePnP to get rvecs and tvecs for each board
                for board_idx, cam in enumerate(cams):
                    p = cam.geometry.projection().getParameters().flatten()
                    d = cam.geometry.projection().distortion().getParameters().flatten()

                    print(f"init projection from kalibr inside (board #{board_idx}):", p)
                    print(f"init distortion from kalibr inside (board #{board_idx}):", d)

                    _, rvec, tvec = cv2.solvePnP(objps[board_idx][i], imgps[board_idx][i], build_camera_matrix(p), d)
                    transformations.append((rvec, tvec))

                print(f"transformations for view #{i}: {transformations}")

                Rs = [cv2.Rodrigues(rvec)[0] for rvec, _ in transformations]
                ts = [tvec for _, tvec in transformations]

                print(f"Rs: {Rs}")
                print(f"ts: {ts}")

                # object points of the current view
                objps_view = [objps[b][i] for b in range(num_boards)]
                imgps_view = [imgps[b][i] for b in range(num_boards)]

                # build our problem for this view
                batch_problem = JointCalibrationTargetOptimizationProblem.from_given_intrinsics(cams,
                                                                                                Rs,
                                                                                                ts,
                                                                                                objpoints=objps_view,
                                                                                                imgpoints=imgps_view)

                print("batch_problem", batch_problem)

                # add problem patch to estimator and solve it (call for "optimize" happens in the C code)
                estimator_return_value = estimator.addBatch(batch_problem, force)

                print("estimator_return_value", estimator_return_value)

                if estimator_return_value.numIterations >= optimizerOptions.maxIterations:
                    sm.logError("Did not converge in maxIterations... restarting...")
                    raise OptimizationDiverged

                success = estimator_return_value.batchAccepted
                if success:
                    sm.logDebug("The estimator accepted this batch")
                    views.append(batch_problem)
                else:
                    sm.logDebug("The estimator did not accept this batch")

                progress.sample()

                # print optimized paramters
                for board_idx, cam in enumerate(cams):
                    d = cam.geometry.projection().distortion().getParameters().flatten()
                    p = cam.geometry.projection().getParameters().flatten()

                    print(f"===[ Optimized board {board_idx} ]=================================================")
                    print(f"[ Cam {board_idx} ] distortion: {d}")
                    print(f"[ Cam {board_idx} ] projection (fx, fy, cx, cy): {p}")
                    print(" ")

        except OptimizationDiverged as e:
            restart_attempts -= 1
            sm.logWarn(
                "Optimization diverged possibly due to a bad initialization. (Do the models fit the lenses well?)")

            if restart_attempts == 0:
                sm.logError("Max. attemps reached... Giving up...")
                break
            else:
                sm.logWarn("Restarting for a new attempt...")





if __name__ == "__main__":
    main()