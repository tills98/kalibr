#!/usr/bin/env python3
import itertools

print("importing libraries")
import sm
import aslam_cv as acv
import aslam_cv_backend as acvb
import kalibr_common as kc
import kalibr_camera_calibration as kcc
import incremental_calibration as ic
import aslam_backend as aopt
from kalibr_camera_calibration.CameraCalibrator import OptimizationDiverged

import cv2
import os
import numpy as np
from scipy.spatial.transform import Rotation
import multiprocessing
import pylab as pl
import argparse
import sys
import random
import signal
import pickle as pkl
import glob


#available models
cameraModels = { 'pinhole-radtan': acvb.DistortedPinhole,
                 'pinhole-equi':   acvb.EquidistantPinhole,
                 'pinhole-fov':    acvb.FovPinhole,
                 'omni-none':      acvb.Omni,
                 'omni-radtan':    acvb.DistortedOmni,
                 'eucm-none':      acvb.ExtendedUnified,
                 'ds-none':        acvb.DoubleSphere}

# DV group ids
CALIBRATION_GROUP_ID = 0
LANDMARK_GROUP_ID = 1
TRANSFORMATION_GROUP_ID = 2

glob_rerrs = []

def build_T(R, t):
    print(t.shape)
    T = np.eye(4)
    T[:3, :3] = R
    T[:3, 3] = t[:,0]

    return T


def build_between_board_vecs(rvec_world1_to_cam, tvec_world1_to_cam, rvec_world2_to_cam, tvec_world2_to_cam):
    """

    :param R_world1_to_cam: 3x1 rotation vector or 3x3 rotation matrix
    :param t_world1_to_cam:
    :param R_world2_to_cam: 3x1 rotation vector or 3x3 rotation matrix
    :param t_world2_to_cam:
    :return:
    """

    # Invert transformations (from world to cam --> cam to world)
    R_world1_to_cam = cv2.Rodrigues(rvec_world1_to_cam)[0] if rvec_world1_to_cam.shape == (3,1) else rvec_world1_to_cam
    R_cam_to_world1 = R_world1_to_cam.T

    R_world2_to_cam = cv2.Rodrigues(rvec_world2_to_cam)[0] if rvec_world2_to_cam.shape == (3,1) else rvec_world2_to_cam
    R_cam_to_world2 = R_world2_to_cam.T

    R_world1_to_world2 = R_cam_to_world2 @ R_world1_to_cam
    t_world1_to_world2 = R_cam_to_world2 @ (tvec_world1_to_cam - tvec_world2_to_cam)

    # Ensure the rotation matrix is orthonormal
    U, _, Vt = np.linalg.svd(R_world1_to_world2)
    R_world1_to_world2 = U @ Vt  # Enforce orthogonality

    rvec_world1_to_world2 = cv2.Rodrigues(R_world1_to_world2)[0]

    return rvec_world1_to_world2, t_world1_to_world2

def build_between_board_T_ex(T_world1_to_cam, T_world2_to_cam):
    """

    :param R_world1_to_cam: 3x1 rotation vector or 3x3 rotation matrix
    :param t_world1_to_cam:
    :param R_world2_to_cam: 3x1 rotation vector or 3x3 rotation matrix
    :param t_world2_to_cam:
    :return:
    """

    # Invert transformations (from world to cam --> cam to world)
    # R_world1_to_cam = cv2.Rodrigues(rvec_world1_to_cam)[0] if rvec_world1_to_cam.shape == (3,1) else rvec_world1_to_cam
    # R_cam_to_world1 = R_world1_to_cam.T
    #
    # R_world2_to_cam = cv2.Rodrigues(rvec_world2_to_cam)[0] if rvec_world2_to_cam.shape == (3,1) else rvec_world2_to_cam
    # R_cam_to_world2 = R_world2_to_cam.T
    #
    # R_world1_to_world2 = R_cam_to_world2 @ R_world1_to_cam
    # t_world1_to_world2 = R_cam_to_world2 @ (tvec_world1_to_cam - tvec_world2_to_cam)
    #
    # return cv2.Rodrigues(R_world1_to_world2)[0], t_world1_to_world2


def build_camera_matrix(p):
    C = np.eye(3)
    C[0,0] = p[0]
    C[1,1] = p[1]
    C[0,2] = p[2]
    C[1,2] = p[3]

    return C



class JointCalibrationTargetOptimizationProblem(ic.CalibrationOptimizationProblem):
    @classmethod
    def from_given_intrinsics(cls, cams, Rs: [np.ndarray], ts: [np.ndarray], objpoints: [np.ndarray], imgpoints: [np.ndarray]) -> ic.CalibrationOptimizationProblem:
        """
        Build the joint calibration target optimization problem for pinhole rad-tan cameras.

        All input parameters should be organized per board (like as follows: [board0, board1, board2, ...])

        :param camera_intrinsics: intrinsics for each board
        :param distortions: distortions for each board
        :param Rs: R for each board
        :param ts: t for each board
        :param objpoints: target points for each board
        :param imgpoints: image points for each board
        :return: Hopefully that what we want
        """

        print("------ problem definition ------")

        num_boards = len(cams)

        print("num_boards", num_boards)

        assert len(Rs) == num_boards
        assert len(ts) == num_boards
        assert len(objpoints) == num_boards
        assert len(imgpoints) == num_boards

        print("cams", cams)

        # create the problem object
        rval = JointCalibrationTargetOptimizationProblem()

        rval.cams = cams
        rval.Rs = Rs
        rval.ts = ts
        rval.objpoints = objpoints
        rval.imgpoints = imgpoints


        rval.rerrs = dict()

        # build cams for each of our shapes
        for i in range(num_boards):
            glob_rerrs.append([])

        R_combs = list(itertools.combinations(enumerate(Rs), 2))
        t_combs = list(itertools.combinations(enumerate(ts), 2))

        # print("R_combs", R_combs)
        # print("t_combs", t_combs)

        rval.Ts_target_cam = dict()

        # add camera design variables to the problem
        for idx, cam in enumerate(cams):
            cam.setDvActiveStatus(True, True, False)
            rval.addDesignVariable(cam.dv.distortionDesignVariable(), CALIBRATION_GROUP_ID)
            rval.addDesignVariable(cam.dv.projectionDesignVariable(), CALIBRATION_GROUP_ID)
            rval.addDesignVariable(cam.dv.shutterDesignVariable(), CALIBRATION_GROUP_ID)

        # add all target-to-cam transformations as design variables to our problem
        for board_idx, (R, t) in enumerate(zip(Rs, ts)):
            sm.r2quat(R)

            T_target_cam = build_T(R, t)
            T_target_cam_tf = sm.Transformation(T_target_cam)
            T_target_cam_dv = aopt.TransformationDv(T_target_cam_tf)
            T_target_cam_ex = T_target_cam_dv.toExpression()

            T_obj = {
                "o": T_target_cam,
                "tf": T_target_cam_tf,
                "dv": T_target_cam_dv,
                "ex": T_target_cam_ex
            }

            rval.Ts_target_cam[board_idx] = T_obj

            for i in range(0, T_target_cam_dv.numDesignVariables()):
                rval.addDesignVariable(T_target_cam_dv.getDesignVariable(i), TRANSFORMATION_GROUP_ID)

        # add all 3D world landmarks as design variables to our problem
        rval.Ps = dict()
        for board_idx in range(num_boards):
            rval.Ps[board_idx] = []

        for board_idx in range(num_boards):
            P_t_hom, P_t_dv, P_t_ex = cls.build_target_coordinate_dvs(objpoints[board_idx])
            
            for i in range(len(P_t_dv)):
                rval.Ps[board_idx].append({
                    "o": objpoints[board_idx][i],
                    "hom": P_t_hom[i],
                    "dv": P_t_dv[i],
                    "ex": P_t_ex[i]
                })

            for p_dv in P_t_dv:
                rval.addDesignVariable(p_dv, LANDMARK_GROUP_ID)

        # add all target-to-target transformations as design variables to our problem
        rval.Ts_target_target = dict()
        for (source_R, target_R), (source_t, target_t) in zip(R_combs, t_combs):
            source_idx = source_R[0]
            target_idx = target_R[0]
            
            R_target1_cam = source_R[1]
            t_target1_cam = target_t[1]
            R_target2_cam = target_R[1]
            t_target2_cam = target_t[1]

            rvec_t1_t2, t_t1_t2 = build_between_board_vecs(R_target1_cam, t_target1_cam, R_target2_cam, t_target2_cam)
            R_t1_t2 = cv2.Rodrigues(rvec_t1_t2)[0]
            # print("R_t1_t2", R_t1_t2)
            # print("t_t1_t2", t_t1_t2)

            sm.r2quat(R_target1_cam)
            sm.r2quat(R_target2_cam)
            sm.r2quat(R_t1_t2)

            T_t1_t2 = build_T(R_t1_t2, t_t1_t2)

            # create design variables for the transformation between the two boards
            T_t1_t2_tf = sm.Transformation(T_t1_t2)
            T_t1_t2_dv = aopt.TransformationDv(T_t1_t2_tf)
            T_t1_t2_ex = T_t1_t2_dv.toExpression()

            T_obj = {
                "o": T_t1_t2,
                "tf": T_t1_t2_tf,
                "dv": T_t1_t2_dv,
                "ex": T_t1_t2_ex
            }

            #rval.Ts_target_target[(source_idx, target_idx)] = T_obj

            # add boards-in-between transformations as design variables to our problem
            #for i in range(0, T_t1_t2_dv.numDesignVariables()):
                #rval.addDesignVariable(T_t1_t2_dv.getDesignVariable(i), TRANSFORMATION_GROUP_ID)

        rerr_idx = 0

        # add basic reprojection errors to our problem
        for b_idx, T_obj in rval.Ts_target_cam.items():
            T_t_cam_ex = T_obj["ex"]

            rval.rerrs[b_idx] = list()

            for y, p_t in zip(imgpoints[b_idx], rval.Ps[b_idx]):
                cam_id = b_idx
                cam = cams[cam_id]

                p_t_ex = p_t["ex"]

                projected_y = T_obj["o"] @ p_t["hom"]
                projected_y_ex = T_t_cam_ex * p_t_ex

                print("projected_y: ", projected_y.flatten())

                # copied from CameraCalibrator -> CalibrationTargetOptimizationProblem
                # \todo pass in the detector uncertainty somehow.
                cornerUncertainty = 1.0
                R = np.eye(2) * cornerUncertainty * cornerUncertainty
                invR = np.linalg.inv(R)

                # y: real image point
                # projected_y_ex: projected image point
                rerr = cam.model.reprojectionError(y, invR, projected_y_ex, cam.dv)
                rerr.idx = rerr_idx

                rerr_idx += 1

                # add blake-zisserman mest
                mest = aopt.BlakeZissermanMEstimator(2.0)
                rerr.setMEstimatorPolicy(mest)

                # add error term to the problem class
                rval.addErrorTerm(rerr)
                rval.rerrs[b_idx].append(rerr)

            break

        # # add all reprojection errors between boards to our problem
        # for (s_idx, t_idx), T_obj in rval.Ts_target_target.items():
        #     T_t1_t2_ex = T_obj["ex"]
        #     T_t1_cam_ex = rval.Ts_target_cam[s_idx]["ex"]
        #     T_t2_cam_ex = rval.Ts_target_cam[t_idx]["ex"]

        #     # copied from CameraCalibrator -> CalibrationTargetOptimizationProblem
        #     # \todo pass in the detector uncertainty somehow.
        #     cornerUncertainty = 1.0
        #     R = np.eye(2) * cornerUncertainty * cornerUncertainty
        #     invR = np.linalg.inv(R)

        #     rval.rerrs[s_idx] = list()

        #     for y, p_t1 in zip(imgpoints[s_idx], rval.Ps[s_idx]):
        #         cam_id = s_idx
        #         cam = cams[cam_id]

        #         p_t1_ex = p_t1["ex"]

        #         #projected_y_ex = T_t2_cam_ex * T_t1_t2_ex * p_t1_ex
        #         projected_y_ex = T_t1_cam_ex * p_t1_ex

        #         # y: real image point
        #         # projected_y_ex: projected image point
        #         rerr = cam.model.reprojectionError(y, invR, projected_y_ex, cam.dv)
        #         rerr.idx = rerr_idx

        #         rerr_idx += 1

        #         # add blake-zisserman mest
        #         mest = aopt.BlakeZissermanMEstimator(2.0)
        #         rerr.setMEstimatorPolicy(mest)

        #         glob_rerrs[s_idx].append(rerr)

        #         # add error term to the problem class
        #         rval.addErrorTerm(rerr)
        #         rval.rerrs[s_idx].append(rerr)

        sm.logDebug("Adding a view with {0} cameras and {1} error terms".format(len(rval.rerrs), rerr_idx))

        return rval

    @classmethod
    def build_camera_geometry(self, camera_intrinsics, distortions):
        params = np.array([camera_intrinsics[0, 0], camera_intrinsics[1, 1], camera_intrinsics[0, 2], camera_intrinsics[1, 2]])
        dist_coeff = distortions[0]

        dist = acv.RadialTangentialDistortion(dist_coeff[0], dist_coeff[1], dist_coeff[2], dist_coeff[3])

        proj = acv.DistortedPinholeProjection(params[0], params[1],
                                              params[2], params[3],
                                              6040, 4080,
                                              dist)

        geometry = acv.DistortedPinholeCameraGeometry(proj)

        return geometry

    @classmethod
    def build_target_coordinate_dvs(cls, objpoints):
        P_t_hom = []
        P_t_dv = []
        P_t_ex = []

        for p in objpoints:
            p_t_hom = sm.toHomogeneous(p)
            p_t_dv = aopt.HomogeneousPointDv(p_t_hom)  # self.target.point(i) is a point from the target expressed in the target frame (_points in GridCalibrationTargetAprilgrid.(hpp/cpp))
            p_t_dv.setActive(True)
            p_t_ex = p_t_dv.toExpression()
            P_t_hom.append(p_t_hom)
            P_t_dv.append(p_t_dv)
            P_t_ex.append(p_t_ex)

        return P_t_hom, P_t_dv, P_t_ex


def main():
    base_path = "/data"

    print("load data")
    
    # load intrinsics, extrinsics and 3d points
    mtx6 = np.load(f"{base_path}/mtx6.npy")
    dist6 = np.load(f"{base_path}/dist6.npy")
    rvecs6 = np.load(f"{base_path}/rvecs6.npy")
    tvecs6 = np.load(f"{base_path}/tvecs6.npy")
    #with open(f"{base_path}/res/objpoints6.pkl", "rb") as f: objpoints6 = pkl.load(f)
    #with open(f"{base_path}/res/imgp6.pkl", "rb") as f: imgp6 = pkl.load(f)

    mtx7 = np.load(f"{base_path}/mtx7.npy")
    dist7 = np.load(f"{base_path}/dist7.npy")
    rvecs7 = np.load(f"{base_path}/rvecs7.npy")
    tvecs7 = np.load(f"{base_path}/tvecs7.npy")
    #with open(f"{base_path}/res/objpoints7.pkl", "rb") as f: objpoints7 = pkl.load(f)
    #with open(f"{base_path}/res/imgp7.pkl", "rb") as f: imgp7 = pkl.load(f)

    mtx8 = np.load(f"{base_path}/mtx8.npy")
    dist8 = np.load(f"{base_path}/dist8.npy")
    rvecs8 = np.load(f"{base_path}/rvecs8.npy")
    tvecs8 = np.load(f"{base_path}/tvecs8.npy")
    #with open(f"{base_path}/res/objpoints8.pkl", "rb") as f: objpoints8 = pkl.load(f)
    #with open(f"{base_path}/res/imgp8.pkl", "rb") as f: imgp8 = pkl.load(f)

    # set number of boards
    num_boards = 3

    # load image and object points from our calibration data
    print("load image and objpoints")
    imgps = []
    objps = []

    for b in range(num_boards):
        imgps.append([])
        objps.append([])

        # our board files are numerated by their shape on one axis (0 -> 6 -> 6x6 board, ...)
        bproj = b + 6

        print("b", b)
        print("bproj", bproj)
        print("path", f"{base_path}/imgpoints/board{bproj}_imgp_*")

        imgp_files = glob.glob(f"{base_path}/imgpoints/board{bproj}_imgp_*")
        imgp_files.sort()

        objp_files = glob.glob(f"{base_path}/objpoints/board{bproj}_objp_*")
        objp_files.sort()

        print("files", imgp_files)
        print("files", objp_files)

        for file in imgp_files:
            imgp = np.loadtxt(f"{file}")
            imgps[b].append(imgp)

        for file in objp_files:
            o = np.loadtxt(f"{file}")
            objps[b].append(o)

    # calculate views
    num_views = len(imgps[0])  # all board entries have the same amount of images
    print(f"amount of views per board (boardid: imagepoints / worldpoints):")
    for b in range(num_boards):
        print(f" - {b}: {len(imgps[b])} / {len(objps[b])}")

    # setup intrinsics and distortions
    print("setup intrinsics and distortions")
    camera_intrinsics = [mtx6, mtx7, mtx8]
    distortions = [dist6, dist7, dist8]

    print(" - camera_intrinsics:")
    for b in range(num_boards):
        print(f"   -> {b}: {camera_intrinsics[b]}")
    print(" - distortions:")
    for b in range(num_boards):
        print(f"   -> {b}: {distortions[b]}")


    # limit attempts
    restart_attempts = 3

    while True:
        try:
            # build camera geometry
            cams = []

            print("setup camera geometry for each board calibration")
            for i in range(num_boards):
                cam_geometry = JointCalibrationTargetOptimizationProblem.build_camera_geometry(camera_intrinsics[i], distortions[i])
                cam = kcc.CameraGeometry(cameraModel=cameraModels["pinhole-radtan"], targetConfig=None, dataset=None,
                                         geometry=cam_geometry)
                cams.append(cam)
                glob_rerrs.append([])

            # init incremental estimator
            estimator = ic.IncrementalEstimator(CALIBRATION_GROUP_ID)
            linearSolverOptions = estimator.getLinearSolverOptions()
            optimizerOptions = estimator.getOptimizerOptions()
            estimatorOptions = estimator.getOptions()

            # set linear solver options
            linearSolverOptions.columnScaling = True
            linearSolverOptions.verbose = True
            linearSolverOptions.epsSVD = 1e-6

            # set optimizer options
            optimizerOptions.maxIterations = 50
            optimizerOptions.nThreads = max(1, multiprocessing.cpu_count()-6)
            #optimizerOptions.nThreads = 1
            optimizerOptions.verbose = True

            # set estimator options
            estimatorOptions.verbose = True

            # futher options
            force = False

            # ----
            views = []

            progress = sm.Progress2(num_views)
            progress.sample()

            init_ps = []
            init_ds = []

            for board_idx, cam in enumerate(cams):
                p = cam.geometry.projection().getParameters().flatten()
                d = cam.geometry.projection().distortion().getParameters().flatten()

                init_ps.append(p)
                init_ds.append(d)

            # append problems for each image
            for i in range(num_views):
                print("=======================================================================")
                print(f"Optimize projection and distortion for view #{i} ...")

                # solvePnP for the rvecs and tvecs
                # print optimized paramters

                transformations = []

                # solvePnP to get rvecs and tvecs for each board
                for board_idx, cam in enumerate(cams):
                    p = cam.geometry.projection().getParameters().flatten()
                    d = cam.geometry.projection().distortion().getParameters().flatten()

                    print(f"init projection from kalibr inside (board #{board_idx}):", p)
                    print(f"init distortion from kalibr inside (board #{board_idx}):", d)

                    _, rvec, tvec = cv2.solvePnP(objps[board_idx][i], imgps[board_idx][i], build_camera_matrix(p), d)
                    transformations.append((rvec, tvec))

                # print(f"transformations for view #{i}: {transformations}")

                Rs = [cv2.Rodrigues(rvec)[0] for rvec, _ in transformations]
                ts = [tvec for _, tvec in transformations]

                # print(f"Rs: {Rs}")
                # print(f"ts: {ts}")

                # object points of the current view
                objps_view = [objps[b][i] for b in range(num_boards)]
                imgps_view = [imgps[b][i] for b in range(num_boards)]

                # build our problem for this view
                batch_problem = JointCalibrationTargetOptimizationProblem.from_given_intrinsics(cams,
                                                                                                Rs,
                                                                                                ts,
                                                                                                objpoints=objps_view,
                                                                                                imgpoints=imgps_view)

                # print("batch_problem", batch_problem)

                # add problem patch to estimator and solve it (call for "optimize" happens in the C code)
                estimator_return_value = estimator.addBatch(batch_problem, force)

                # print("estimator_return_value", estimator_return_value)

                if estimator_return_value.numIterations >= optimizerOptions.maxIterations:
                    sm.logError("Did not converge in maxIterations... restarting...")
                    raise OptimizationDiverged

                success = estimator_return_value.batchAccepted
                if success:
                    sm.logDebug("The estimator accepted this batch")
                    views.append(batch_problem)
                else:
                    sm.logDebug("The estimator did not accept this batch")

                progress.sample()

                # print optimized paramters
                for board_idx, cam in enumerate(cams):
                    d = cam.geometry.projection().distortion().getParameters().flatten()
                    p = cam.geometry.projection().getParameters().flatten()

                    print(f"===[ Initial board {board_idx} ]=================================================")
                    print(f"[ Cam {board_idx} ] distortion: {init_ds[board_idx]}")
                    print(f"[ Cam {board_idx} ] projection (fx, fy, cx, cy): {init_ps[board_idx]}")
                    print(" ")
                    print(f"===[ Optimized board {board_idx} ]=================================================")
                    print(f"[ Cam {board_idx} ] distortion: {d}")
                    print(f"[ Cam {board_idx} ] projection (fx, fy, cx, cy): {p}")
                    print(" ")

        except OptimizationDiverged as e:
            restart_attempts -= 1
            sm.logWarn(
                "Optimization diverged possibly due to a bad initialization. (Do the models fit the lenses well?)")

            if restart_attempts == 0:
                sm.logError("Max. attemps reached... Giving up...")
                break
            else:
                sm.logWarn("Restarting for a new attempt...")





if __name__ == "__main__":
    main()